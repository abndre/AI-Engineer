{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89839038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from evaluate import load  # biblioteca Hugging Face 'evaluate'\n",
    "\n",
    "# Carrega o modelo e tokenizer (exemplo com GPT-2)\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Texto de entrada\n",
    "input_text = \"Once upon a time\"\n",
    "\n",
    "# Encode the input text, generate and decode it\n",
    "input_text_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = model.generate(input_text_ids, max_length=20)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Text: \", generated_text)\n",
    "\n",
    "# Load and compute the perplexity score\n",
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "results = perplexity.compute(model_id=\"gpt2\", predictions=generated_text)\n",
    "print(\"Perplexity: \", results['mean_perplexity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d242afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "bleu = load(\"bleu\")\n",
    "input_sentence_1 = \"Hola, ¿cómo estás?\"\n",
    "\n",
    "reference_1 = [\n",
    "     [\"Hello, how are you?\", \"Hi, how are you?\"]\n",
    "     ]\n",
    "\n",
    "input_sentences_2 = [\"Hola, ¿cómo estás?\", \"Estoy genial, gracias.\"]\n",
    "\n",
    "references_2 = [\n",
    "     [\"Hello, how are you?\", \"Hi, how are you?\"],\n",
    "     [\"I'm great, thanks.\", \"I'm great, thank you.\"]\n",
    "     ]\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "\n",
    "# Translate the first input sentence then calucate the BLEU metric for translation quality\n",
    "translated_output = translator(input_sentence_1)\n",
    "\n",
    "translated_sentence = translated_output[0]['translation_text']\n",
    "\n",
    "print(\"Translated:\", translated_sentence)\n",
    "\n",
    "results = bleu.compute(predictions=[translated_sentence], references=reference_1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the input sentences, extract the translated text, and compute BLEU score\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "\n",
    "translated_outputs = translator(input_sentences_2)\n",
    "\n",
    "predictions = [translated_output[\"translation_text\"] for translated_output in translated_outputs]\n",
    "print(predictions)\n",
    "\n",
    "results = bleu.compute(predictions=predictions, references=references_2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5410f151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andre\\miniconda3\\envs\\huggingface_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE results:  {'rouge1': np.float64(0.7719298245614034), 'rouge2': np.float64(0.6181818181818182), 'rougeL': np.float64(0.736842105263158), 'rougeLsum': np.float64(0.736842105263158)}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "# Load the rouge metric\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "predictions = [\"\"\"Pluto is a dwarf planet in our solar system, located in the Kuiper Belt beyond Neptune, and was formerly considered the ninth planet until its reclassification in 2006.\"\"\"]\n",
    "references = [\"\"\"Pluto is a dwarf planet in the solar system, located in the Kuiper Belt beyond Neptune, and was previously deemed as a planet until it was reclassified in 2006.\"\"\"]\n",
    "\n",
    "# Calculate the rouge scores between the predicted and reference summaries\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(\"ROUGE results: \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a047e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install evaluate\n",
    "#%pip install nltk rouge_score absl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdebf49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 7.02k/7.02k [00:00<?, ?B/s]\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Andre\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meteor:  0.37180012567275916\n"
     ]
    }
   ],
   "source": [
    "meteor = evaluate.load(\"meteor\")\n",
    "\n",
    "generated = [\"The burrow stretched forward like a narrow corridor for a while, then plunged abruptly downward, so quickly that Alice had no chance to stop herself before she was tumbling into an extremely deep shaft.\"]\n",
    "reference = [\"The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that Alice had not a moment to think about stopping herself before she found herself falling down a very deep well.\"]\n",
    "\n",
    "# Compute and print the METEOR score\n",
    "results = meteor.compute(predictions=generated, references=reference)\n",
    "print(\"Meteor: \", results['meteor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39f9c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.67k/5.67k [00:00<00:00, 6.04MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM results:  {'exact_match': np.float64(0.25)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the metric\n",
    "exact_match = evaluate.load(\"exact_match\")\n",
    "\n",
    "predictions = [\"It's a wonderful day\", \"I love dogs\", \"DataCamp has great AI courses\", \"Sunshine and flowers\"]\n",
    "references = [\"What a wonderful day\", \"I love cats\", \"DataCamp has great AI courses\", \"Sunsets and flowers\"]\n",
    "\n",
    "# Compute the exact match and print the results\n",
    "results = exact_match.compute(references=references, predictions=predictions)\n",
    "print(\"EM results: \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6895f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.08k/6.08k [00:00<?, ?B/s]\n",
      "WARNING:evaluate_modules.metrics.evaluate-measurement--toxicity.2390290fa0bf6d78480143547c6b08f3d4f8805b249df8c7a8e80d0ce8e3778b.toxicity:Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n",
      "c:\\Users\\Andre\\miniconda3\\envs\\huggingface_env\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Andre\\.cache\\huggingface\\hub\\models--facebook--roberta-hate-speech-dynabench-r4-target. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicities (user_1): [0.00013486345415003598, 0.00013348401989787817]\n",
      "Toxicities (user_2):  [0.0001355926360702142, 0.00013771136582363397]\n",
      "Maximum toxicity (user_1): 0.00013486345415003598\n",
      "Maximum toxicity (user_2):  0.00013771136582363397\n",
      "Toxicity ratio (user_1): 0.0\n",
      "Toxicity ratio (user_2):  0.0\n"
     ]
    }
   ],
   "source": [
    "user_1=['Everyone that tried it love it', 'This artist is a true genius, pure talent']\n",
    "user_2=[\"Nobody i've talked to likes this product\", 'Terrible singer']\n",
    "toxicity_metric = evaluate.load(\"toxicity\")\n",
    "# Calculate the individual toxicities\n",
    "toxicity_1 = toxicity_metric.compute(predictions=user_1)\n",
    "toxicity_2 = toxicity_metric.compute(predictions=user_2)\n",
    "print(\"Toxicities (user_1):\", toxicity_1['toxicity'])\n",
    "print(\"Toxicities (user_2): \", toxicity_2['toxicity'])\n",
    "\n",
    "# Calculate the maximum toxicities\n",
    "toxicity_1_max = toxicity_metric.compute(predictions=user_1,aggregation=\"maximum\")\n",
    "toxicity_2_max = toxicity_metric.compute(predictions=user_2,aggregation=\"maximum\")\n",
    "print(\"Maximum toxicity (user_1):\", toxicity_1_max['max_toxicity'])\n",
    "print(\"Maximum toxicity (user_2): \", toxicity_2_max['max_toxicity'])\n",
    "\n",
    "# Calculate the toxicity ratios\n",
    "toxicity_1_ratio = toxicity_metric.compute(predictions=user_1,aggregation=\"ratio\")\n",
    "toxicity_2_ratio = toxicity_metric.compute(predictions=user_1,aggregation=\"ratio\")\n",
    "print(\"Toxicity ratio (user_1):\", toxicity_1_ratio['toxicity_ratio'])\n",
    "print(\"Toxicity ratio (user_2): \", toxicity_2_ratio['toxicity_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbafb34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 8.41k/8.41k [00:00<?, ?B/s]\n",
      "c:\\Users\\Andre\\miniconda3\\envs\\huggingface_env\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Andre\\.cache\\huggingface\\hub\\models--sasha--regardv3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity in group 1:\n",
      " {'regard': [[{'label': 'neutral', 'score': 0.9586172103881836}, {'label': 'negative', 'score': 0.020241964608430862}, {'label': 'positive', 'score': 0.014409039169549942}, {'label': 'other', 'score': 0.006731739267706871}], [{'label': 'positive', 'score': 0.83542400598526}, {'label': 'other', 'score': 0.12411251664161682}, {'label': 'neutral', 'score': 0.03053131513297558}, {'label': 'negative', 'score': 0.009932112880051136}]]}\n",
      "Polarity in group 2:\n",
      " {'regard': [[{'label': 'negative', 'score': 0.9745951890945435}, {'label': 'other', 'score': 0.017152613028883934}, {'label': 'neutral', 'score': 0.007746343966573477}, {'label': 'positive', 'score': 0.0005058045499026775}], [{'label': 'neutral', 'score': 0.7666088938713074}, {'label': 'negative', 'score': 0.10047446191310883}, {'label': 'positive', 'score': 0.07146850973367691}, {'label': 'other', 'score': 0.061448223888874054}]]}\n",
      "Polarity comparison between groups:\n",
      " {'regard_difference': {'neutral': 0.10739664384163916, 'negative': -0.5224477867595851, 'positive': 0.3889293654356152, 'other': 0.026121709495782852}}\n"
     ]
    }
   ],
   "source": [
    "group1 = ['abc are described as loyal', \n",
    "          'abc are honest but kind']\n",
    "group2 = ['abc are known for being confrontational',\n",
    "          'abc are very blunt']\n",
    "# Load the regard and regard-comparison metrics\n",
    "regard = evaluate.load(\"regard\")\n",
    "regard_comp = evaluate.load(\"regard\", \"compare\")\n",
    "\n",
    "# Compute the regard (polarities) of each group separately\n",
    "polarity_results_1 = regard.compute(data=group1)\n",
    "print(\"Polarity in group 1:\\n\", polarity_results_1)\n",
    "polarity_results_2 = regard.compute(data=group2)\n",
    "print(\"Polarity in group 2:\\n\", polarity_results_2)\n",
    "\n",
    "# Compute the relative regard between the two groups for comparison\n",
    "polarity_results_comp = regard_comp.compute(data=group1, references=group2)\n",
    "print(\"Polarity comparison between groups:\\n\", polarity_results_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968822ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
